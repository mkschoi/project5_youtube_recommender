{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos_cleaned_v6 = pd.read_csv('../Data/df_videos_cleaned_v6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the functions (Need to put these into a separate .py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_custom_stopwords(df):\n",
    "    '''\n",
    "    Input: Cleaned dataframe\n",
    "    Output: Dataframe with custom stopwords removed\n",
    "    '''\n",
    "    def final_preprocessing(cleaned_text):\n",
    "        preprocessed_text_11 = eval(cleaned_text)\n",
    "       \n",
    "        nlp.Defaults.stop_words |= {'uh','yeah','man','um','oh','guy','maybe','bye'}\n",
    "        stopwords = nlp.Defaults.stop_words\n",
    "        \n",
    "        preprocessed_text_12 = [(word.lower(), pos) for word, pos in preprocessed_text_11 \n",
    "                                    if word.lower() not in stopwords] \n",
    "        \n",
    "        return preprocessed_text_12\n",
    "    \n",
    "    df['Transcript'] = df['Transcript'].apply(final_preprocessing)\n",
    "            \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_term_matrix(df, vectorizer):\n",
    "    '''\n",
    "    Input: Cleaned dataframe (after removing custom stopwords) and type of vectorizer\n",
    "    Output: Document-term matrix\n",
    "    '''\n",
    "    # Take the words out of the (word, POS) tuple, vectorize, and fit-transform into a matrix\n",
    "    word_list = [[word[0] for word in doc] for doc in df['Transcript']]\n",
    "    vec = vectorizer(tokenizer=lambda doc:doc, lowercase=False, min_df=2, max_df=0.3)\n",
    "    matrix = vec.fit_transform(word_list).toarray()\n",
    "        \n",
    "    return matrix, vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_model(matrix, model, num_topics, num_words):\n",
    "    '''\n",
    "    Input: Document-term matrix, type of topic model, number of topics, and number of words is each topic\n",
    "    Output: a list of lists containing topic words\n",
    "    '''\n",
    "    if model == NMF:\n",
    "        model = model(num_topics)\n",
    "    elif model == LatentDirichletAllocation:\n",
    "        model = model(n_components=num_topics)\n",
    "        \n",
    "    doc_topic = model.fit_transform(matrix)\n",
    "    topic_word = model.components_\n",
    "    \n",
    "    words = document_term_matrix(df_videos_cleaned_v7, CountVectorizer)[1]\n",
    "    t_model = topic_word.argsort(axis=1)[:, -1:-(num_words+1):-1]\n",
    "    top_topic_words = [[words[i] for i in topic] for topic in t_model]\n",
    "        \n",
    "    return top_topic_words, doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_of_adjectives(df):\n",
    "    '''\n",
    "    Input: Cleaned dataframe (after removing custom stopwords) \n",
    "    Output: Dataframe with only adjectives in the transcript corpus\n",
    "    '''\n",
    "    def adjectives(cleaned_text):\n",
    "        \n",
    "        preprocessed_text_adj = [(word.lower(), pos) for word, pos in cleaned_text \n",
    "                                    if pos=='ADJ'] \n",
    "        \n",
    "        return preprocessed_text_adj\n",
    "    \n",
    "    df['Transcript'] = df['Transcript'].apply(adjectives)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_assignment(df):\n",
    "    '''\n",
    "    Input: Cleaned dataframe (after removing custom stopwords)\n",
    "    Output: Dataframe with topic and topic coefficient added\n",
    "    '''\n",
    "    doc_topic = topic_model(X_tfidf, NMF, 6, 7)[1]\n",
    "    topic_coeff = [round(np.max(coeffs),3) for coeffs in doc_topic]\n",
    "    topic = list(doc_topic.argmax(axis=1))\n",
    "    \n",
    "    topic_keys = {0:'General', 1:'Valuation', 2:'Competitive Moats', 3:'Passive Investing', \n",
    "                  4:'Financial statement Analysis', 5:'Technology stocks'}\n",
    "    \n",
    "    topic_name = [topic_keys.get(topic_index,'') for topic_index in topic]\n",
    "    \n",
    "    df['Topic'] = topic_name\n",
    "    df['Topic Coefficient'] = topic_coeff\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df_str):\n",
    "    '''\n",
    "    Input: Name of a dataframe in a string format\n",
    "    Output: CSV file of the dataframe saved into the Data folder\n",
    "    '''\n",
    "    eval(df_str).to_csv('../Data/{}.csv'.format(df_str), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove custom stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos_cleaned_v7 = remove_custom_stopwords(df_videos_cleaned_v6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating document-term matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv = document_term_matrix(df_videos_cleaned_v7, CountVectorizer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = document_term_matrix(df_videos_cleaned_v7, TfidfVectorizer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling - Entire corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization (NMF), CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sort', 'buffett', 'cheap', 'multiple', 'moat', 'team', 'answer'],\n",
       " ['option', 'leap', 'decay', 'cover', 'spread', 'view', 'ge'],\n",
       " ['equal', 'divide', 'discount', 'constant', 'present', 'zero', 'minus'],\n",
       " ['graham', 'buffett', 'security', 'ben', 'street', 'intrinsic', 'warren'],\n",
       " ['bank', 'support', 'news', 'report', 'resistance', 'break', 'chart'],\n",
       " ['etf', 'holding', 'index', 'tax', 'sector', 'expense', 'goal']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_nmf_cv = topic_model(X_cv, NMF, 6, 7)[0]\n",
    "topics_nmf_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization (NMF), TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['buffett', 'sort', 'technical', 'warren', 'bank', 'trader', 'index'],\n",
       " ['constant',\n",
       "  'formula',\n",
       "  'divide',\n",
       "  'discount',\n",
       "  'present',\n",
       "  'equal',\n",
       "  'calculate'],\n",
       " ['moat', 'mode', 'competitive', 'economic', 'brand', 'competitor', 'castle'],\n",
       " ['etf', 'holding', 'index', 'vanguard', 'expense', 'johnson', 'etfs'],\n",
       " ['ebitda', 'enterprise', 'multiple', 'irr', 'statement', 'forecast', 'da'],\n",
       " ['tesla', 'apple', 'pe', 'amazon', 'car', 'vehicle', 'facebook']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_nmf_tfidf = topic_model(X_tfidf, NMF, 6, 7)[0]\n",
    "topics_nmf_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA), CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['discount',\n",
       "  'divide',\n",
       "  'equal',\n",
       "  'calculate',\n",
       "  'formula',\n",
       "  'present',\n",
       "  'constant'],\n",
       " ['brand', 'game', 'sort', 'china', 'team', 'customer', 'moat'],\n",
       " ['pe', 'bank', 'statement', 'sheet', 'multiple', 'apple', 'ebitda'],\n",
       " ['etf', 'tesla', 'index', 'tax', 'sector', 'holding', 'goal'],\n",
       " ['buffett', 'sort', 'warren', 'graham', 'cheap', 'berkshire', 'write'],\n",
       " ['moat', 'trader', 'economic', 'technical', 'chart', 'trend', 'news']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_lda_cv = topic_model(X_cv, LatentDirichletAllocation, 6, 7)[0]\n",
    "topics_lda_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling - Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos_cleaned_v7_adj = df_videos_cleaned_v7.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos_cleaned_adj = corpus_of_adjectives(df_videos_cleaned_v7_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv_adj = document_term_matrix(df_videos_cleaned_adj, CountVectorizer)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf_adj = document_term_matrix(df_videos_cleaned_adj, TfidfVectorizer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization (NMF), CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['airtel', 'bourbon', 'badmind', 'allocation', 'convex', 'captured'],\n",
       " ['brokerages', 'brandy', 'bureau', 'airbus', 'candid', 'callaghan'],\n",
       " ['arrogance', 'alumnus', 'canadianbased', 'allergy', 'breaks', 'att'],\n",
       " ['bertrand', 'brandy', 'bourbon', 'canadianbased', 'alum', 'assumed'],\n",
       " ['cognitive', 'browse', 'arcanum', 'buffy', 'brandy', 'calibrate'],\n",
       " ['boxer', 'bedell', 'brokerdealer', 'blab', 'acknowledge', 'blackness']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_nmf_cv_adj = topic_model(X_cv_adj, NMF, 6, 6)[0]\n",
    "topics_nmf_cv_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization (NMF), TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bedell', 'brokerdealer', 'airtel', 'brokerages', 'boxer', 'burg'],\n",
       " ['alumnus', 'arrogance', 'canadianbased', 'brokerages', 'allergy', 'cameron'],\n",
       " ['bertrand', 'assumed', 'commerce', 'canadianbased', 'alum', 'compliant'],\n",
       " ['allocation', 'arcanum', 'coauthored', 'contradictory', 'benefited', 'aqui'],\n",
       " ['cognitive', 'adolescent', 'ag', 'bureau', 'brokerages', 'browse'],\n",
       " ['brandy', 'brand', 'bourbon', 'buffer', 'calibrate', 'acknowledge']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_nmf_tfidf_adj = topic_model(X_tfidf_adj, NMF, 6, 6)[0]\n",
    "topics_nmf_tfidf_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA), CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['arrogance',\n",
       "  'alumnus',\n",
       "  'canadianbased',\n",
       "  'bertrand',\n",
       "  'assumed',\n",
       "  'brokerages'],\n",
       " ['bourbon', 'airtel', 'brandy', 'bertrand', 'buffer', 'brand'],\n",
       " ['allocation', 'brokerages', 'arcanum', 'allergy', 'bureau', 'coauthored'],\n",
       " ['boxer', 'airtel', 'convex', 'badmind', 'clout', 'airbus'],\n",
       " ['bedell', 'buffy', 'brokerdealer', 'burger', 'blackness', 'burg'],\n",
       " ['cognitive', 'brand', 'calibrate', 'brandy', 'bonfire', 'browse']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_lda_cv_adj = topic_model(X_cv_adj, LatentDirichletAllocation, 6, 6)[0]\n",
    "topics_lda_cv_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning topics and coefficients to videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos_cleaned_v8 = topic_assignment(df_videos_cleaned_v7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the modified dataframe into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv('df_videos_cleaned_v8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
