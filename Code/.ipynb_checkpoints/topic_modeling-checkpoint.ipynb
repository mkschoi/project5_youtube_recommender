{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos_cleaned_v6 = pd.read_csv('../Data/df_videos_cleaned_v6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the functions (Need to put these into a separate .py file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_custom_stopwords(df):\n",
    "    '''\n",
    "    Input: Cleaned dataframe\n",
    "    Output: Dataframe with custom stopwords removed\n",
    "    '''\n",
    "    def final_preprocessing(cleaned_text):\n",
    "        preprocessed_text_11 = eval(cleaned_text)\n",
    "       \n",
    "        nlp.Defaults.stop_words |= {'uh','yeah','man','um','oh','guy'}\n",
    "        stopwords = nlp.Defaults.stop_words\n",
    "        \n",
    "        preprocessed_text_12 = [(word.lower(), pos) for word, pos in preprocessed_text_11 \n",
    "                                    if word.lower() not in stopwords] \n",
    "        \n",
    "        return preprocessed_text_12\n",
    "    \n",
    "    df['Transcript'] = df['Transcript'].apply(final_preprocessing)\n",
    "            \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_term_matrix(df, vectorizer):\n",
    "    '''\n",
    "    Input: Cleaned dataframe (after removing custom stopwords) and type of vectorizer\n",
    "    Output: Document-term matrix\n",
    "    '''\n",
    "    # Take the words out of the (word, POS) tuple, vectorize, and fit-transform into a matrix\n",
    "    word_list = [[word[0] for word in doc] for doc in df['Transcript']]\n",
    "    vec = vectorizer(tokenizer=lambda doc:doc, lowercase=False, min_df=2, max_df=0.5)\n",
    "    matrix = vec.fit_transform(word_list).toarray()\n",
    "        \n",
    "    return matrix, vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_model(matrix, model, num_topics, num_words):\n",
    "    '''\n",
    "    Input: Document-term matrix, type of topic model, number of topics, and number of words is each topic\n",
    "    Output: a list of lists containing topic words\n",
    "    '''\n",
    "    if model == NMF:\n",
    "        model = model(num_topics)\n",
    "    elif model == LatentDirichletAllocation:\n",
    "        model = model(n_components=num_topics)\n",
    "        \n",
    "    doc_topic = model.fit_transform(matrix)\n",
    "    topic_word = model.components_\n",
    "    \n",
    "    words = document_term_matrix(df_videos_cleaned_v7, CountVectorizer)[1]\n",
    "    t_model = topic_word.argsort(axis=1)[:, -1:-(num_words+1):-1]\n",
    "    top_topic_words = [[words[i] for i in topic] for topic in t_model]\n",
    "        \n",
    "    return top_topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove custom stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos_cleaned_v7 = remove_custom_stopwords(df_videos_cleaned_v6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating document-term matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv = document_term_matrix(df_videos_cleaned_v7, CountVectorizer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = document_term_matrix(df_videos_cleaned_v7, TfidfVectorizer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling - Entire corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization (NMF), CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['question', 'sort', 'world', 'maybe', 'industry', 'capital'],\n",
       " ['dividend', 'equal', 'plus', 'constant', 'model', 'flow'],\n",
       " ['flow', 'billion', 'debt', 'free', 'revenue', 'ebitda'],\n",
       " ['portfolio', 'dividend', 'etf', 'fund', 'yield', 'income'],\n",
       " ['trade', 'fundamental', 'analysis', 'support', 'news', 'level'],\n",
       " ['ratio', 'pe', 'current', 'profit', 'book', 'equity'],\n",
       " ['option', 'leap', 'trade', 'month', 'risk', 'longterm'],\n",
       " ['graham', 'fund', 'buffett', 'asset', 'book', 'analysis']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model(X_cv, NMF, 8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization (NMF), TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mike/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['question', 'book', 'sort', 'risk', 'buffett', 'maybe'],\n",
       " ['dividend', 'yield', 'portfolio', 'income', 'increase', 'cent'],\n",
       " ['flow', 'billion', 'debt', 'ebitda', 'revenue', 'free'],\n",
       " ['moat', 'advantage', 'mode', 'competitive', 'economic', 'brand'],\n",
       " ['analysis', 'fundamental', 'technical', 'trader', 'ratio', 'chart'],\n",
       " ['ratio', 'model', 'discount', 'formula', 'calculate', 'flow'],\n",
       " ['music', 'foreign', 'applause', 'bye', 'thank', 'backbone'],\n",
       " ['etf', 'fund', 'portfolio', 'index', 'vanguard', 'mutual']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model(X_tfidf, NMF, 8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA), CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dividend', 'portfolio', 'flow', 'ratio', 'fund', 'billion'],\n",
       " ['apex', 'roblox', 'tally', 'ebooks', 'asean', 'erp'],\n",
       " ['music', 'applause', 'browne', 'mack', 'atman', 'spear'],\n",
       " ['oakmark', 'sprout', 'corning', 'obstacles', 'fab', 'nygren'],\n",
       " ['akamai', 'coinbase', 'cranberry', 'tattooed', 'ipof', 'emotors'],\n",
       " ['coal', 'keeper', 'ground', 'bury', 'rook', 'extract'],\n",
       " ['foreign', 'music', 'splunk', 'bulldog', 'rodent', 'meticulous'],\n",
       " ['hcmc', 'momo', 'dorothy', \"c'm\", 'negra', 'samba']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model(X_tfidf, LatentDirichletAllocation, 8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA), TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dividend', 'portfolio', 'flow', 'ratio', 'fund', 'billion'],\n",
       " ['hcmc', 'roblox', 'indistinguishable', 'hifi', 'misquote', 'flightsafety'],\n",
       " ['gyration', 'coal', 'ebooks', 'erp', 'fab', 'kramer'],\n",
       " ['apex', 'corning', 'shovels', 'rebirth', 'rias', 'tenured'],\n",
       " ['oakmark', 'strait', 'bulldog', 'nygren', 'autozone', 'bismarck'],\n",
       " ['music', 'foreign', 'applause', 'asean', 'paddle', 'thank'],\n",
       " ['groupon', 'momo', 'proterra', 'rodent', 'keeper', 'ipof'],\n",
       " ['lilu', 'diffident', 'martina', 'akamai', 'snicker', 'amit']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model(X_tfidf, LatentDirichletAllocation, 8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling - Adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA) - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling - Nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-negative matrix factorization, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA) - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
